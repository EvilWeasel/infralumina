# NEVER USE THIS FILE
# USE THIS AS A TEMPLATE FOR YOUR OWN .env FILES
# AND IGNORE YOUR OWN .env FILES IN .gitignore
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY=
# Optional legacy fallback supported by code:
# NEXT_PUBLIC_SUPABASE_ANON_KEY=

DATABASE_URL=

# AI Create Incident (P0-08)
# Local OpenAI-compatible endpoint (llama.cpp server)
LOCAL_LLM_BASE_URL=http://localhost:8080/v1
LOCAL_LLM_MODEL=qwen2.5-3b-instruct-q4_k_m.gguf
# Optional: only required if your local endpoint enforces auth
# LOCAL_LLM_API_KEY=
